# ğŸ§© Job Market Analytics Pipeline

## ğŸ“– Overview
**Job Market Analytics Pipeline** is an end-to-end data engineering and analytics project that transforms raw, unstructured recruitment data into a clean, relational **MySQL database**, and visualizes job market insights through **Power BI** dashboards.  

This project helps recruitment firms and analysts explore hiring trends, job types, and in-demand skills across industries â€” turning messy data into meaningful intelligence.

---

## ğŸ¯ Project Objectives
- ğŸ”¹ Consolidate fragmented job datasets into a single, structured database  
- ğŸ”¹ Automate data cleaning, transformation, and schema standardization  
- ğŸ”¹ Create interactive Power BI dashboards for actionable insights  
- ğŸ”¹ Optimize for performance to handle 700K+ records efficiently  

---

## ğŸ§± Database Schema
| Column Name | Description |
|--------------|-------------|
| `Job_id` | Unique identifier for each job posting |
| `Job_title` | Title or designation of the job |
| `Job_field` | Functional area (e.g., Data Science, Data Engineering) |
| `Company_name` | Name of the hiring organization |
| `Job_location` | City / State / Remote |
| `Job_posting_date` | Date when the job was first posted |
| `Job_level` | Experience level (Entry / Mid / Senior) |
| `Job_type` | Work mode (On-site / Hybrid / Remote) |
| `Job_skills` | Required or preferred technical skills |
| `Job_employment_type` | Employment nature (Permanent / Contract / Internship etc.) |
| `Summary` | Short description or responsibilities |

---

## âš™ï¸ Tech Stack
| Layer | Tools / Technologies |
|--------|----------------------|
| **Data Processing** | Python (Pandas, NumPy) |
| **Database** | MySQL |
| **ETL & Integration** | PyODBC / MySQL Connector |
| **Visualization** | Power BI (M Language + DAX) |
| **Performance Handling** | Chunk-based data ingestion |

---

## ğŸ§¹ Data Transformation Highlights
<details>
<summary>ğŸ”§ Expand to view details</summary>

- ğŸ§© **Normalization** â€” Merged and aligned multiple data sources under one schema  
- ğŸ§¼ **Cleaning** â€” Removed duplicates, nulls, and invalid records  
- ğŸ§  **Categorization (Power BI M-Code)**  
  - Derived `Job_employment_type` from keywords like *full-time*, *contract*, *internship*, etc.  
  - Classified `Job_title` into consistent categories (e.g., *Data Analyst*, *Cloud Engineer*, *Software Engineer*) using Power Query conditional logic  
- âš™ï¸ **Optimization** â€” Chunk-based inserts to handle >700,000 rows efficiently in Python  

</details>

---

## ğŸ“Š Power BI Visualizations
<details>
<summary>ğŸ“ˆ Click to expand the list of dashboards</summary>

1. **Hiring Trends Over Time** â†’ Job postings per year for trend analysis  
2. **Distribution of Job Types** â†’ Breakdown of remote, hybrid, and on-site roles  
3. **Top Job Types per Country & Year** â†’ Regional hiring insights  
4. **Average Number of Companies Hiring Over Time** â†’ Measures market activity  
5. **Top 3 Job Fields by Year** â†’ Identifies high-demand sectors annually  
6. **Most In-Demand Skills** â†’ Visual representation of skill frequency  

</details>

---

## ğŸš€ Key Features
- ğŸ’¾ Handles datasets with 700K+ records effortlessly  
- ğŸ§® Automated ETL from CSV â†’ MySQL â†’ Power BI  
- ğŸ§± Clean mapping between relational schema and Power BI visuals  
- âš¡ Optimized report performance with efficient data modeling  

---

## ğŸ“ Folder Structure
```bash
job-market-analytics-pipeline/
â”‚
â”œâ”€â”€ data2/ # ğŸ“Š Raw job data files (CSV)
â”œâ”€â”€ project objectives/ # ğŸ¯ Problem statement files (PDF)
â”œâ”€â”€ transformation/ # âš™ï¸ DAX, M-code transformations & Python ETL scripts
â”œâ”€â”€ visualization/ # ğŸ“ˆ Power BI (.pbix) dashboards
â””â”€â”€ README.md # ğŸ“ Project overview (this file)
